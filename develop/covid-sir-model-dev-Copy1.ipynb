{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.stats\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import sunode\n",
    "import sunode.wrappers.as_theano\n",
    "from pymc3.ode import DifferentialEquation\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "import datetime\n",
    "import shelve\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lembrar que este e um projeto com foco em aprender inferencia na pratica, nao eng. nao precisa ser tudo tao robusto, lembrar da materia do cara em como fazer DS testavel e agil (e este so no 2o momento tambem hahaha)\n",
    "\n",
    "class COVID_data():\n",
    " \n",
    "    def __init__(self, country='US', Population = 328.2e6):\n",
    "        # bela api para pegar casos do instituto JH. So preciso, no maximo, colocar opcao de nao salcar localmente dados\n",
    "        confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "        self.confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "        deaths_url =  'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "        self.deaths = pd.read_csv(deaths_url, sep=',')\n",
    "        path_to_save = ''\n",
    " \n",
    "        # ------------------------- Country for inference -------------------\n",
    " \n",
    "        self.country = country\n",
    "        self.N = Population   # Population of the country\n",
    "                         # Germany - 83.7e6\n",
    "                         # US - 328.2e6\n",
    "    # colocar opcao de definir datas mais flexiveis, vai depender das opcoes de modelagem\n",
    "    def get_dates(self, data_begin='7/11/20', data_end='7/20/20'):\n",
    " \n",
    "        # ------------------------- Date for inference ----------------------#\n",
    "        self.data_begin = data_begin  #Take the data until yesterday\n",
    "        self.data_end = data_end\n",
    "        self.num_days_to_predict = 14\n",
    "        confirmed_cases = self.confirmed_cases\n",
    "        country = self.country\n",
    "        self.cases_country = confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == country]\n",
    "        self.cases_obs = np.array(confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == country, data_begin:data_end])[0]\n",
    " \n",
    "        print(\"------------ Cases for selected period ----------- \",self.cases_obs)\n",
    " \n",
    "        date_data_end = confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == self.country, data_begin:data_end].columns[-1]\n",
    "        month, day, year = map(int,date_data_end.split('/'))\n",
    "        date_data_end = datetime.date(year+2000, month, day)\n",
    "        date_today = date_data_end + datetime.timedelta(days=1)\n",
    "        print(\"------------- Cases yesterday ({}): {} and day before yesterday: {} ------------\".format(date_data_end.isoformat(), *self.cases_obs[:-3:-1]))\n",
    "        self.num_days = len(self.cases_obs)\n",
    " \n",
    "        day_before_start = dt.strptime(data_end, '%m/%d/%y') + datetime.timedelta(days=-1)\n",
    "        day_before_start_cases = np.array(self.cases_country.loc[:, day_before_start.strftime('%-m/%-d/%-y')])\n",
    "        print(\"------------ Day before start and cases for that date ------------\", day_before_start, day_before_start_cases)\n",
    "        future_days_begin = dt.strptime(data_end, '%m/%d/%y') + datetime.timedelta(days=1)\n",
    "        future_days_end = future_days_begin + datetime.timedelta(days=self.num_days_to_predict)\n",
    "        self.future_days_begin_s = future_days_begin.strftime('%-m/%-d/%-y')\n",
    "        self.future_days_end_s = future_days_end.strftime('%-m/%-d/%-y')\n",
    "        print(\"------------- Future date begin and end -------------\",self.future_days_begin_s, self.future_days_end_s)\n",
    "        self.future_days = np.array(self.cases_country.loc[:, self.future_days_begin_s : self.future_days_end_s])[0]\n",
    "        print(\"------------- Future days cases ------------\", self.future_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIR_model():\n",
    " \n",
    "    def __init__(self, covid_data) :\n",
    " \n",
    "        # ------------------------- Covid_data object -----------------------#\n",
    "        self.covid_data = covid_data\n",
    "        # ------------------------- Setup SIR model, but has to be called explicitly to run ------------------------#\n",
    "        self.setup_SIR_model()\n",
    " \n",
    "    def SIR_non_normalized(self, y, t, p):\n",
    "        ds = -p[0] * y[0] * y[1] /self.covid_data.N\n",
    "        di = p[0] * y[0] * y[1] / self.covid_data.N  -  p[1] * y[1]\n",
    "        return [ds, di]\n",
    " \n",
    "    def setup_SIR_model(self):\n",
    "        self.time_range = np.arange(0,len(self.covid_data.cases_obs),1)\n",
    "        self.I0 = self.covid_data.cases_obs[0]\n",
    "        self.S0 = self.covid_data.N - self.I0\n",
    " \n",
    "        # SIR model\n",
    "        self.sir_model_non_normalized = DifferentialEquation(\n",
    "            func=self.SIR_non_normalized,\n",
    "            times=self.time_range[1:],\n",
    "            n_states=2,\n",
    "            n_theta=2,\n",
    "            t0=0)\n",
    " \n",
    "    def run_SIR_model(self, n_samples, n_tune, likelihood, prior):\n",
    "        # ------------------------- Metadata --------------------------------#\n",
    "        now = dt.now()\n",
    "        timenow = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "        self.filename = 'sir_' + self.covid_data.data_begin.replace('/','-') + '_' + \\\n",
    "            self.covid_data.data_end.replace('/','-') + '_' + timenow\n",
    "        self.likelihood = likelihood\n",
    "        self.n_samples = n_samples\n",
    "        self.n_tune = n_tune\n",
    "        self.likelihood = likelihood\n",
    "        self.prior = prior\n",
    "        # ------------------------ Write out metadata while the model is running -------------------#\n",
    "        metadata_db_filename = 'metadata_db.db'\n",
    " \n",
    "        t = time.time()\n",
    " \n",
    "        with pm.Model() as model4:\n",
    "            sigma = pm.HalfCauchy('sigma', likelihood['sigma'], shape=1)\n",
    "            lam = pm.Lognormal('lambda', prior['lam'], prior['lambda_std'])\n",
    "            mu = pm.Lognormal('mu', prior['mu'], prior['mu_std'])\n",
    " \n",
    "            res = self.sir_model_non_normalized(y0=[self.S0, self.I0], theta=[lam, mu])\n",
    " \n",
    "            if(likelihood['distribution'] == 'lognormal'):\n",
    "                Y = pm.Lognormal('Y', mu=pm.math.log(res.take(0, axis=1)), sigma=sigma, observed=self.covid_data.cases_obs[1:])\n",
    "            else:\n",
    "                Y = pm.StudentT( \"Y\",  nu=likelihood['nu'],       # likelihood distribution of the data\n",
    "                        mu=res.take(0, axis=1),     # likelihood distribution mean, these are the predictions from SIR\n",
    "                        sigma=sigma,\n",
    "                        observed=cases_obs[1:]\n",
    "                        )\n",
    "            trace = pm.sample(self.n_samples, tune=self.n_tune, target_accept=0.9, \n",
    "                              chains=20, cores=4#2 for some reason, it isnt working on 2 cores\n",
    "                             )\n",
    "            data = az.from_pymc3(trace=trace)\n",
    " \n",
    "        t1 = time.time() - t\n",
    "        az.plot_posterior(data, round_to=2, hdi_prob=0.95)\n",
    "        axes = az.plot_trace(trace)\n",
    "        fig = axes.ravel()[0].figure\n",
    "        fig.savefig(self.filename)\n",
    " \n",
    "        self.metadata_db = shelve.open(metadata_db_filename)\n",
    "        self.metadata_db[self.filename] = {'type': 'sir', 'samples': n_samples,\n",
    "                                    'tune': n_tune,\n",
    "                                    'elapsed_time': t1,\n",
    "                                    'finished': dt.now().strftime(\"%d-%m-%Y_%H:%M:%S\"),\n",
    "                                    'likelihood': likelihood,\n",
    "                                    'prior': prior }\n",
    "        self.metadata_db.close()\n",
    " \n",
    " \n",
    " \n",
    "class SIR_model_sunode():\n",
    " \n",
    "    def __init__(self, covid_data) :\n",
    " \n",
    "        # ------------------------- Covid_data object -----------------------#\n",
    "        self.covid_data = covid_data\n",
    "        # ------------------------- Setup SIR model, but has to be called explicitly to run ------------------------#\n",
    "        self.setup_SIR_model()\n",
    " \n",
    "    def SIR_sunode(self, t, y, p):\n",
    "        return {\n",
    "            'S': -p.lam * y.S * y.I,\n",
    "            'I': p.lam * y.S * y.I - p.mu * y.I,\n",
    "        }\n",
    " \n",
    "    def setup_SIR_model(self):\n",
    "        self.time_range = np.arange(0,len(self.covid_data.cases_obs),1)\n",
    "        self.I0 = self.covid_data.cases_obs[0]\n",
    "        self.S0 = self.covid_data.N - self.I0\n",
    "        self.S_init = self.S0 / self.covid_data.N\n",
    "        self.I_init = self.I0 / self.covid_data.N\n",
    "        self.cases_obs_scaled = self.covid_data.cases_obs / self.covid_data.N\n",
    " \n",
    " \n",
    "    def run_SIR_model(self, n_samples, n_tune, likelihood, prior):\n",
    "        # ------------------------- Metadata --------------------------------#\n",
    "        now = dt.now()\n",
    "        timenow = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "        self.filename = 'sir_' + self.covid_data.data_begin.replace('/','-') + '_' + \\\n",
    "            self.covid_data.data_end.replace('/','-') + '_' + timenow\n",
    "        self.likelihood = likelihood\n",
    "        self.n_samples = n_samples\n",
    "        self.n_tune = n_tune\n",
    "        self.likelihood = likelihood\n",
    "        self.prior = prior\n",
    "        # ------------------------ Write out metadata while the model is running -------------------#\n",
    "        metadata_db_filename = 'metadata_db.db'\n",
    " \n",
    "        t = time.time()\n",
    " \n",
    "        with pm.Model() as model4:\n",
    "            sigma = pm.HalfCauchy('sigma', self.likelihood['sigma'], shape=1)\n",
    "            lam_mu = np.log(self.prior['lam']) + self.prior['lambda_std']**2\n",
    "            mu_mu = np.log(self.prior['mu']) + self.prior['mu_std']**2\n",
    "            lam = pm.Lognormal('lambda', lam_mu , self.prior['lambda_std']) # 1.5, 1.5\n",
    "            mu = pm.Lognormal('mu', mu_mu, self.prior['mu_std'])           # 1.5, 1.5\n",
    " \n",
    "            res, _, problem, solver, _, _ = sunode.wrappers.as_theano.solve_ivp(\n",
    "            y0={\n",
    "            # The initial conditions of the ode. Each variable\n",
    "            # needs to specify a theano or numpy variable and a shape.\n",
    "            # This dict can be nested.\n",
    "                'S': (self.S_init, ()),\n",
    "                'I': (self.I_init, ()),},\n",
    "            params={\n",
    "            # Each parameter of the ode. sunode will only compute derivatives\n",
    "            # with respect to theano variables. The shape needs to be specified\n",
    "            # as well. It it infered automatically for numpy variables.\n",
    "            # This dict can be nested.\n",
    "                'lam': (lam, ()),\n",
    "                'mu': (mu, ()),\n",
    "                '_dummy': (np.array(1.), ())},\n",
    "            # A functions that computes the right-hand-side of the ode using\n",
    "            # sympy variables.\n",
    "            rhs=self.SIR_sunode,\n",
    "            # The time points where we want to access the solution\n",
    "            tvals=self.time_range,\n",
    "            t0=self.time_range[0]\n",
    "            )\n",
    "            if(likelihood['distribution'] == 'lognormal'):\n",
    "                I = pm.Lognormal('I', mu=res['I'], sigma=sigma, observed=self.cases_obs_scaled)\n",
    "            elif(likelihood['distribution'] == 'normal'):\n",
    "                I = pm.Normal('I', mu=res['I'], sigma=sigma, observed=self.cases_obs_scaled)\n",
    "            elif(likelihood['distribution'] == 'students-t'):\n",
    "                I = pm.StudentT( \"I\",  nu=likelihood['nu'],       # likelihood distribution of the data\n",
    "                        mu=res['I'],     # likelihood distribution mean, these are the predictions from SIR\n",
    "                        sigma=sigma,\n",
    "                        observed=self.cases_obs_scaled\n",
    "                        )\n",
    " \n",
    "            theano.printing.Print('S')(res['S'])\n",
    "            print('Problem',problem)\n",
    "            print('Solver',solver)\n",
    " \n",
    "            R = 1 - (res['I'] + res['S'])\n",
    "            #S = 1 - (res['I'][1:])\n",
    "            #theano.printing.Print('R')(R)\n",
    "            R0 = pm.Deterministic('R0',lam/mu)\n",
    " \n",
    "            step = pm.Metropolis()\n",
    "            trace = pm.sample(self.n_samples, tune=self.n_tune, chains=4, cores=4)\n",
    "            data = az.from_pymc3(trace=trace)\n",
    " \n",
    "        t1 = time.time() - t\n",
    "        az.plot_posterior(data, round_to=2, point_estimate='mode', credible_interval=0.95)\n",
    "        axes = az.plot_trace(trace)\n",
    "        fig = axes.ravel()[0].figure\n",
    "        fig.savefig(self.filename)\n",
    "        \n",
    "        fig = ff.create_distplot([trace['R0']], bin_size=0.5, group_labels=['x'])\n",
    " \n",
    "        # Add title\n",
    "        fig.update_layout(title_text='Curve and Rug Plot')\n",
    "        fig.update_xaxes(range=[0,7])\n",
    "              \n",
    " \n",
    "        self.metadata_db = shelve.open(metadata_db_filename)\n",
    "        self.metadata_db[self.filename] = {'type': 'sir', 'samples': n_samples,\n",
    "                                    'tune': n_tune,\n",
    "                                    'elapsed_time': t1,\n",
    "                                    'finished': dt.now().strftime(\"%d-%m-%Y_%H:%M:%S\"),\n",
    "                                    'likelihood': likelihood,\n",
    "                                    'prior': prior }\n",
    "        self.metadata_db.close()\n",
    "        return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Cases for selected period -----------  [3252949 3311373 3370303 3438354 3506444 3582310 3654546 3717082 3777538\n",
      " 3839645]\n",
      "------------- Cases yesterday (2020-07-20): 3839645 and day before yesterday: 3777538 ------------\n",
      "------------ Day before start and cases for that date ------------ 2020-07-19 00:00:00 [3777538]\n",
      "------------- Future date begin and end ------------- 7/21/20 8/4/20\n",
      "------------- Future days cases ------------ [3904106 3974685 4043130 4116449 4181402 4236218 4293001 4359413 4431286\n",
      " 4498752 4567464 4623665 4669233 4714734 4773508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a3ce2398617>:59: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(self.n_samples, tune=self.n_tune, target_accept=0.9,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (20 chains in 4 jobs)\n",
      "NUTS: [mu, lambda, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10200 00:00<00:00 Sampling 20 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Chain 0 failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/parallel_sampling.py\", line 116, in _unpickle_step_method\n    self._step_method = pickle.loads(self._step_method)\nAttributeError: Can't get attribute 'SIR_model' on <module '__main__' (built-in)>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/parallel_sampling.py\", line 135, in run\n    self._unpickle_step_method()\n  File \"/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/parallel_sampling.py\", line 118, in _unpickle_step_method\n    raise ValueError(unpickle_error)\nValueError: The model could not be unpickled. This is required for sampling with more than one core and multiprocessing context spawn or forkserver.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: The model could not be unpickled. This is required for sampling with more than one core and multiprocessing context spawn or forkserver.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e208f7b24ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'distribution'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'lognormal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sigma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lam'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mu'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda_std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mu_std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msir_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_SIR_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-3a3ce2398617>\u001b[0m in \u001b[0;36mrun_SIR_model\u001b[0;34m(self, n_samples, n_tune, likelihood, prior)\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcases_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         )\n\u001b[0;32m---> 59\u001b[0;31m             trace = pm.sample(self.n_samples, tune=self.n_tune, target_accept=0.9, \n\u001b[0m\u001b[1;32m     60\u001b[0m                               \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;31m#2 for some reason, it isnt working on 2 cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                              )\n",
      "\u001b[0;32m/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparallel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_sampler_stats\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_draws\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pymc3/lib/python3.8/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chain %s failed.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"writing_done\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Chain 0 failed."
     ]
    }
   ],
   "source": [
    "# -------- Usage --------#\n",
    "covid_obj = COVID_data('US', Population=328.2e6)\n",
    "covid_obj.get_dates(data_begin='7/11/20', data_end='7/20/20')\n",
    "sir_model = SIR_model(covid_obj)\n",
    "likelihood = {'distribution': 'lognormal', 'sigma': 2}\n",
    "prior= {'lam': 0.4, 'mu': 1/8, 'lambda_std': 0.5, 'mu_std': 0.5 }\n",
    "sir_model.run_SIR_model(n_samples=500, n_tune=10, likelihood=likelihood, prior=prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
